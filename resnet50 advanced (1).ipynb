{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "815a5861-5c7e-4fe4-a9fa-4d4a64e23ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c34fc704-6b25-477a-9f11-841da0b67482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, img_size=(224, 224)):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_names = os.listdir(data_dir)\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            X.append(img)\n",
    "            y.append(class_index)\n",
    "    return np.array(X), np.array(y), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ed0f1a0-1063-49bb-a219-1ad0f72d58f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(num_classes, embedding_dim=128):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding = Dense(embedding_dim, activation=None, name='embedding')(x)\n",
    "    embedding_normalized = Lambda(lambda x: K.l2_normalize(x, axis=1), name='embedding_normalized')(embedding)\n",
    "    \n",
    "    # Fully connected layers for classification\n",
    "    fc = Dense(1024, activation='relu')(embedding_normalized)\n",
    "    fc = Dense(512, activation='relu')(fc)\n",
    "    output = Dense(num_classes, activation='softmax', name='classification')(fc)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=[output, embedding_normalized])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a31c39-e97e-4390-942d-8aa66b28e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def triplet_loss(y_true, y_pred, alpha=0.2):\n",
    "    anchor, positive, negative = y_pred[:, 0:128], y_pred[:, 128:256], y_pred[:, 256:]\n",
    "    pos_dist = K.sum(K.square(anchor - positive), axis=1)\n",
    "    neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    loss = K.maximum\n",
    "    (basic_loss, 0.0)\n",
    "    return K.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee8aae9c-9d12-49e6-afee-1ca807338d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dir, val_dir, epochs=10, batch_size=32):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'classification': 'categorical_crossentropy',\n",
    "            'embedding_normalized': triplet_loss\n",
    "        },\n",
    "        loss_weights={\n",
    "            'classification': 1.0,\n",
    "            'embedding_normalized': 0.5\n",
    "        },\n",
    "        metrics={\n",
    "            'classification': ['accuracy', TopKCategoricalAccuracy(k=1, name='top_1_accuracy')]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // batch_size,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dad7fb58-5e41-435b-ac27-2c84e354cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings(model, X):\n",
    "    return model.predict(X)[1]  # Return the embedding output\n",
    "\n",
    "def calculate_similarity(embeddings1, embeddings2):\n",
    "    return cosine_similarity(embeddings1, embeddings2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c701faf-932c-4f50-842d-35651dae24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Face detection and recognition\n",
    "def detect_and_recognize(image_path, model, class_names):\n",
    "    face_cascade = cv2.CascadeClassifier(r\"C:\\Users\\hp\\Desktop\\ml\\haarcascade_frontalface_default.xml\")\n",
    "    img = cv2.imread(r\"C:\\Users\\hp\\Desktop\\ml\\what.jpeg\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        face = img[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "        face = preprocess_input(face)\n",
    "        \n",
    "        prediction = model.predict(face)\n",
    "        class_index = np.argmax(prediction)\n",
    "        class_name = class_names[class_index]\n",
    "        confidence = prediction[0][class_index]\n",
    "        \n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f\"{class_name} ({confidence:.2f})\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Face Recognition', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d019f941-fd93-4502-be0b-395123e010c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93 images belonging to 5 classes.\n",
      "Found 25 images belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7s/step - classification_accuracy: 0.2985 - classification_top_1_accuracy: 0.2985 - loss: 1.5937 - val_classification_accuracy: 0.3200 - val_classification_top_1_accuracy: 0.3200 - val_loss: 1.5346\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - classification_accuracy: 0.4375 - classification_top_1_accuracy: 0.4375 - loss: 1.5484 - val_classification_accuracy: 0.5600 - val_classification_top_1_accuracy: 0.5600 - val_loss: 1.4792\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - classification_accuracy: 0.6667 - classification_top_1_accuracy: 0.6667 - loss: 1.4285 - val_classification_accuracy: 0.7200 - val_classification_top_1_accuracy: 0.7200 - val_loss: 1.3248\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step - classification_accuracy: 0.8621 - classification_top_1_accuracy: 0.8621 - loss: 1.3095 - val_classification_accuracy: 0.6800 - val_classification_top_1_accuracy: 0.6800 - val_loss: 1.2289\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - classification_accuracy: 0.7332 - classification_top_1_accuracy: 0.7332 - loss: 1.1270 - val_classification_accuracy: 0.6800 - val_classification_top_1_accuracy: 0.6800 - val_loss: 1.0493\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - classification_accuracy: 0.7812 - classification_top_1_accuracy: 0.7812 - loss: 1.0240 - val_classification_accuracy: 0.8000 - val_classification_top_1_accuracy: 0.8000 - val_loss: 0.9552\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - classification_accuracy: 0.9037 - classification_top_1_accuracy: 0.9037 - loss: 0.8220 - val_classification_accuracy: 0.8400 - val_classification_top_1_accuracy: 0.8400 - val_loss: 0.7590\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - classification_accuracy: 0.9062 - classification_top_1_accuracy: 0.9062 - loss: 0.6400 - val_classification_accuracy: 0.8400 - val_classification_top_1_accuracy: 0.8400 - val_loss: 0.6566\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - classification_accuracy: 0.8666 - classification_top_1_accuracy: 0.8666 - loss: 0.5586 - val_classification_accuracy: 0.8800 - val_classification_top_1_accuracy: 0.8800 - val_loss: 0.5094\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - classification_accuracy: 0.9375 - classification_top_1_accuracy: 0.9375 - loss: 0.3132 - val_classification_accuracy: 0.8800 - val_classification_top_1_accuracy: 0.8800 - val_loss: 0.4596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "Top-1 Accuracy: 0.8000\n",
      "Fully Connected Accuracy: 0.8000\n",
      "Embedding Similarities:\n",
      "[[ 1.0000002   0.77094626  0.51415807  0.3062411   0.6927728   0.4831488\n",
      "   0.33051085  0.14298996  0.6647019   0.20563939  0.6429514   0.5069053\n",
      "   0.5900402   0.47949895  0.703919    0.46234637 -0.01424095  0.07460039\n",
      "   0.16512197  0.23846084  0.2900459   0.08409538 -0.02808679 -0.00631722\n",
      "  -0.14280717]\n",
      " [ 0.77094626  1.0000001   0.5863014   0.26832145  0.726564    0.64916915\n",
      "   0.45329073  0.304592    0.71574616  0.49395856  0.8462175   0.46289203\n",
      "   0.71053684  0.6578344   0.87934965  0.35708103 -0.06515568 -0.02243525\n",
      "   0.17228475  0.1351164   0.10774911 -0.18607126 -0.22437494 -0.15238003\n",
      "  -0.343748  ]\n",
      " [ 0.51415807  0.5863014   1.         -0.02042066  0.5418078   0.7482823\n",
      "   0.30737972  0.25701007  0.63785934  0.48125488  0.79861677  0.6135055\n",
      "   0.8160548   0.7894162   0.7859867   0.15526858 -0.11503872 -0.09944816\n",
      "  -0.02475942  0.13299485  0.03806318 -0.02402572 -0.08741926  0.01154554\n",
      "  -0.22138089]\n",
      " [ 0.3062411   0.26832145 -0.02042066  1.0000002   0.36709246  0.14861418\n",
      "   0.38366228  0.29762074  0.19036393  0.33386892  0.09618112  0.13608015\n",
      "   0.01700251  0.06723815  0.13686042  0.6346716   0.63379914  0.5278461\n",
      "   0.7552185   0.6882051   0.45251822  0.16961631  0.28497678  0.30329952\n",
      "   0.2301759 ]\n",
      " [ 0.6927728   0.726564    0.5418078   0.36709246  1.0000002   0.6202223\n",
      "   0.47130883  0.35837376  0.578626    0.5651475   0.72414196  0.43509358\n",
      "   0.6242079   0.5230964   0.70293564  0.36523426  0.06798068  0.0217206\n",
      "   0.25153294  0.26809284  0.11129914 -0.11213882 -0.13768905 -0.05885432\n",
      "  -0.19801167]\n",
      " [ 0.4831488   0.64916915  0.7482823   0.14861418  0.6202223   0.9999998\n",
      "   0.49683353  0.5290619   0.67792517  0.71716744  0.7893489   0.74401325\n",
      "   0.7881709   0.79163694  0.80083007  0.29649007  0.18958475  0.13919248\n",
      "   0.20923346  0.32100347  0.14893684  0.12059499 -0.0143524   0.22991417\n",
      "  -0.14727317]\n",
      " [ 0.33051085  0.45329073  0.30737972  0.38366228  0.47130883  0.49683353\n",
      "   1.0000002   0.73109543  0.43012846  0.5963634   0.38365796  0.38753536\n",
      "   0.3574391   0.45498928  0.4648735   0.39808077  0.3927195   0.24140406\n",
      "   0.3863967   0.4485808   0.27579212  0.09554216  0.07434469  0.19261134\n",
      "   0.04296491]\n",
      " [ 0.14298996  0.304592    0.25701007  0.29762074  0.35837376  0.5290619\n",
      "   0.73109543  1.          0.38223508  0.72241294  0.2890493   0.32574415\n",
      "   0.2915916   0.43617895  0.4141993   0.24753916  0.42691374  0.16166067\n",
      "   0.34220436  0.41243893  0.17814283  0.10939349  0.10328963  0.26696932\n",
      "   0.09344179]\n",
      " [ 0.6647019   0.71574616  0.63785934  0.19036393  0.578626    0.67792517\n",
      "   0.43012846  0.38223508  0.9999998   0.4384226   0.6579395   0.560667\n",
      "   0.6403774   0.6921322   0.7338522   0.4125715   0.08492272  0.07202864\n",
      "   0.16755332  0.20312907  0.1091403   0.1581484  -0.0438379   0.07705548\n",
      "  -0.19337642]\n",
      " [ 0.20563939  0.49395856  0.48125488  0.33386892  0.5651475   0.71716744\n",
      "   0.5963634   0.72241294  0.4384226   0.9999998   0.5500525   0.35641158\n",
      "   0.52199155  0.59942126  0.5809115   0.26205617  0.33299747  0.13478602\n",
      "   0.37072253  0.4066836   0.13514839 -0.11285222 -0.05507668  0.13232946\n",
      "  -0.13103633]\n",
      " [ 0.6429514   0.8462175   0.79861677  0.09618112  0.72414196  0.7893489\n",
      "   0.38365796  0.2890493   0.6579395   0.5500525   1.0000002   0.591127\n",
      "   0.897447    0.74550766  0.9041326   0.18289562 -0.15761982 -0.11250144\n",
      "   0.03045842  0.07761977  0.02280835 -0.17899702 -0.19781163 -0.1302462\n",
      "  -0.35678634]\n",
      " [ 0.5069053   0.46289203  0.6135055   0.13608015  0.43509358  0.74401325\n",
      "   0.38753536  0.32574415  0.560667    0.35641158  0.591127    1.\n",
      "   0.6888771   0.6045502   0.61945975  0.33785707  0.20390497  0.25404805\n",
      "   0.14422952  0.30748433  0.26490182  0.43922582  0.2297038   0.38886175\n",
      "   0.11267124]\n",
      " [ 0.5900402   0.71053684  0.8160548   0.01700251  0.6242079   0.7881709\n",
      "   0.3574391   0.2915916   0.6403774   0.52199155  0.897447    0.6888771\n",
      "   1.          0.7565774   0.8567443   0.14723128 -0.10553259 -0.0901236\n",
      "   0.02432559  0.1125052   0.14650437 -0.00881883 -0.05078957 -0.00509284\n",
      "  -0.21164055]\n",
      " [ 0.47949895  0.6578344   0.7894162   0.06723815  0.5230964   0.79163694\n",
      "   0.45498928  0.43617895  0.6921322   0.59942126  0.74550766  0.6045502\n",
      "   0.7565774   1.0000001   0.7950358   0.28067148  0.0726635   0.04197266\n",
      "   0.15299942  0.2471355   0.12901789 -0.00524416 -0.02386684  0.08972471\n",
      "  -0.1516148 ]\n",
      " [ 0.703919    0.87934965  0.7859867   0.13686042  0.70293564  0.80083007\n",
      "   0.4648735   0.4141993   0.7338522   0.5809115   0.9041326   0.61945975\n",
      "   0.8567443   0.7950358   1.0000001   0.30639067 -0.04263079 -0.03972386\n",
      "   0.11511255  0.16695105  0.08006684 -0.10348151 -0.17470442 -0.06670219\n",
      "  -0.30875102]\n",
      " [ 0.46234637  0.35708103  0.15526858  0.6346716   0.36523426  0.29649007\n",
      "   0.39808077  0.24753916  0.4125715   0.26205617  0.18289562  0.33785707\n",
      "   0.14723128  0.28067148  0.30639067  1.          0.5909952   0.6624502\n",
      "   0.6628268   0.616289    0.50183815  0.39243144  0.3544336   0.4132651\n",
      "   0.28058162]\n",
      " [-0.01424095 -0.06515568 -0.11503872  0.63379914  0.06798068  0.18958475\n",
      "   0.3927195   0.42691374  0.08492272  0.33299747 -0.15761982  0.20390497\n",
      "  -0.10553259  0.0726635  -0.04263079  0.5909952   1.0000001   0.74805295\n",
      "   0.8020434   0.8157746   0.53282946  0.47782397  0.5263431   0.6478446\n",
      "   0.51092035]\n",
      " [ 0.07460039 -0.02243525 -0.09944816  0.5278461   0.0217206   0.13919248\n",
      "   0.24140406  0.16166067  0.07202864  0.13478602 -0.11250144  0.25404805\n",
      "  -0.0901236   0.04197266 -0.03972386  0.6624502   0.74805295  1.0000004\n",
      "   0.74344647  0.6618285   0.5594367   0.51640844  0.5179245   0.64714104\n",
      "   0.4911981 ]\n",
      " [ 0.16512197  0.17228475 -0.02475942  0.7552185   0.25153294  0.20923346\n",
      "   0.3863967   0.34220436  0.16755332  0.37072253  0.03045842  0.14422952\n",
      "   0.02432559  0.15299942  0.11511255  0.6628268   0.8020434   0.74344647\n",
      "   1.          0.76856536  0.5720888   0.28810477  0.42422384  0.4960233\n",
      "   0.34059387]\n",
      " [ 0.23846084  0.1351164   0.13299485  0.6882051   0.26809284  0.32100347\n",
      "   0.4485808   0.41243893  0.20312907  0.4066836   0.07761977  0.30748433\n",
      "   0.1125052   0.2471355   0.16695105  0.616289    0.8157746   0.6618285\n",
      "   0.76856536  1.          0.600381    0.35092974  0.43697745  0.5819291\n",
      "   0.4074079 ]\n",
      " [ 0.2900459   0.10774911  0.03806318  0.45251822  0.11129914  0.14893684\n",
      "   0.27579212  0.17814283  0.1091403   0.13514839  0.02280835  0.26490182\n",
      "   0.14650437  0.12901789  0.08006684  0.50183815  0.53282946  0.5594367\n",
      "   0.5720888   0.600381    1.          0.49455383  0.6118639   0.5922318\n",
      "   0.5530047 ]\n",
      " [ 0.08409538 -0.18607126 -0.02402572  0.16961631 -0.11213882  0.12059499\n",
      "   0.09554216  0.10939349  0.1581484  -0.11285222 -0.17899702  0.43922582\n",
      "  -0.00881883 -0.00524416 -0.10348151  0.39243144  0.47782397  0.51640844\n",
      "   0.28810477  0.35092974  0.49455383  0.99999994  0.7282152   0.7492874\n",
      "   0.6649052 ]\n",
      " [-0.02808679 -0.22437494 -0.08741926  0.28497678 -0.13768905 -0.0143524\n",
      "   0.07434469  0.10328963 -0.0438379  -0.05507668 -0.19781163  0.2297038\n",
      "  -0.05078957 -0.02386684 -0.17470442  0.3544336   0.5263431   0.5179245\n",
      "   0.42422384  0.43697745  0.6118639   0.7282152   1.0000002   0.7216155\n",
      "   0.69988227]\n",
      " [-0.00631722 -0.15238003  0.01154554  0.30329952 -0.05885432  0.22991417\n",
      "   0.19261134  0.26696932  0.07705548  0.13232946 -0.1302462   0.38886175\n",
      "  -0.00509284  0.08972471 -0.06670219  0.4132651   0.6478446   0.64714104\n",
      "   0.4960233   0.5819291   0.5922318   0.7492874   0.7216155   1.0000004\n",
      "   0.6602248 ]\n",
      " [-0.14280717 -0.343748   -0.22138089  0.2301759  -0.19801167 -0.14727317\n",
      "   0.04296491  0.09344179 -0.19337642 -0.13103633 -0.35678634  0.11267124\n",
      "  -0.21164055 -0.1516148  -0.30875102  0.28058162  0.51092035  0.4911981\n",
      "   0.34059387  0.4074079   0.5530047   0.6649052   0.69988227  0.6602248\n",
      "   1.0000005 ]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test, num_classes):\n",
    "    y_test_cat = to_categorical(y_test, num_classes)\n",
    "    y_pred, embeddings = model.predict(X_test)\n",
    "    \n",
    "    # Calculate top-1 accuracy\n",
    "    top_1_accuracy = np.mean(np.argmax(y_pred, axis=1) == y_test)\n",
    "    \n",
    "    # Calculate fully connected accuracy\n",
    "    fc_accuracy = model.evaluate(X_test, [y_test_cat, y_test_cat], verbose=0)[1]\n",
    "    \n",
    "    # Calculate embedding similarity\n",
    "    similarities = calculate_similarity(embeddings, embeddings)\n",
    "    \n",
    "    return top_1_accuracy, fc_accuracy, similarities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_dir = r\"C:\\Users\\hp\\Desktop\\ml\\dataset\\train\"\n",
    "    test_dir = r\"C:\\Users\\hp\\Desktop\\ml\\dataset\\val\"\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X_train, y_train, class_names = load_data(train_dir)\n",
    "    X_test, y_test, _ = load_data(test_dir)\n",
    "    \n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    # Convert labels to categorical\n",
    "    y_train_cat = to_categorical(y_train, num_classes)\n",
    "    y_test_cat = to_categorical(y_test, num_classes)\n",
    "    \n",
    "    # Create and compile the model\n",
    "    model = create_model(num_classes)\n",
    "    \n",
    "    # Train the model\n",
    "    model, history = train_model(model, train_dir, test_dir)\n",
    "    \n",
    "    # Save the model\n",
    "    model.save('face_rec_advanced.h5')\n",
    "    \n",
    "    # Evaluate the model\n",
    "    top_1_accuracy, fc_accuracy, similarities = evaluate_model(model, X_test, y_test, num_classes)\n",
    "    \n",
    "    print(f\"Top-1 Accuracy: {top_1_accuracy:.4f}\")\n",
    "    print(f\"Fully Connected Accuracy: {fc_accuracy:.4f}\")\n",
    "    print(\"Embedding Similarities:\")\n",
    "    print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9defede2-efc6-449a-95cb-673ea19ba3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Sample Image Embedding:\n",
      "[[ 4.07301039e-02  1.10394351e-01  8.91054943e-02  8.16061273e-02\n",
      "   9.33263730e-03  9.99042168e-02  9.26797241e-02 -3.97027656e-02\n",
      "  -5.50999977e-02 -1.02053978e-01 -3.90345640e-02  6.07660227e-03\n",
      "  -2.34638993e-02  1.07193060e-01 -9.93901026e-03  4.17066226e-03\n",
      "  -5.90168536e-02 -1.76372554e-03 -1.20428698e-02  6.18927851e-02\n",
      "   1.22242510e-01  1.87546715e-01  8.60504359e-02  2.33807024e-02\n",
      "  -7.82775804e-02 -1.62601650e-01  1.88875735e-01 -2.17130277e-02\n",
      "   3.42852548e-02  9.38646868e-02 -3.43954414e-02  1.13239795e-01\n",
      "   4.42270190e-02  1.27627656e-01  6.58891574e-02  8.01674873e-02\n",
      "   1.20469151e-04 -2.15219352e-02 -3.16444249e-03  3.22635360e-02\n",
      "  -1.22991063e-01 -2.36616120e-01  4.24176231e-02 -5.44497073e-02\n",
      "   1.34413727e-02  1.19682841e-01  1.26599684e-01  1.56316295e-01\n",
      "   2.23493557e-02  7.47089908e-02 -1.28981978e-01  8.89300182e-02\n",
      "  -2.89825033e-02 -6.75112233e-02 -1.20885596e-02 -4.29154374e-02\n",
      "  -7.47759715e-02  8.86056423e-02  1.51447907e-01 -3.39461230e-02\n",
      "   5.79759888e-02  7.76199813e-05 -1.12938900e-02  3.94663550e-02\n",
      "  -3.92197967e-02  3.16390768e-02  5.60098626e-02  7.81851262e-02\n",
      "  -7.72459656e-02 -1.04058161e-01  8.61795023e-02 -3.97168547e-02\n",
      "  -2.15837862e-02  2.38899281e-03 -4.07170057e-02 -1.45072579e-01\n",
      "   8.42847105e-04 -2.45242976e-02 -1.34571522e-01  1.82236105e-01\n",
      "   6.87617064e-02 -1.66806102e-01 -1.27033209e-02  5.41399568e-02\n",
      "  -2.53556985e-02  4.90092076e-02 -9.35966447e-02  2.33576423e-03\n",
      "  -8.44319314e-02  6.38329685e-02 -7.24739220e-04 -2.24409878e-01\n",
      "   6.49060681e-02  6.26327321e-02  1.12857930e-01  1.50868520e-01\n",
      "   1.21048335e-02 -1.27919167e-01 -8.35102051e-03  8.97412747e-03\n",
      "  -1.39988109e-01  2.75667068e-02  4.51735333e-02 -6.90452605e-02\n",
      "   5.23716286e-02 -1.25488818e-01 -7.51560554e-02  1.23361036e-01\n",
      "  -4.52653654e-02  1.08376622e-01  2.15474591e-02  9.16259810e-02\n",
      "  -8.08698311e-02  5.96920811e-02 -1.33308384e-03  1.08887218e-01\n",
      "  -8.30912590e-02 -8.79544467e-02  1.46358311e-01 -5.43699600e-02\n",
      "   2.27887910e-02  3.87571938e-02  1.39890099e-02 -3.46329175e-02\n",
      "   2.07070708e-01  9.42194015e-02 -1.90482333e-01 -1.86592657e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for a sample image\n",
    "sample_image = r'C:\\Users\\hp\\Desktop\\ml\\what.jpeg'\n",
    "img = cv2.imread(sample_image)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)\n",
    "    \n",
    "_, embedding = model.predict(img)\n",
    "print(\"Sample Image Embedding:\")\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeef211-6f21-4db0-835b-1b0abb654e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c7d466-3d33-4c91-888a-b77e89fe9482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6922ab-a022-425c-8611-0ccc968c4137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
